{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"text-align:center;\"> AI for Writing </p>\n![](https://static.scientificamerican.com/sciam/cache/file/C9A31747-FBED-41A5-8820ED507C404BB0_source.jpg)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# develop a web application which accurately calculates the toxicity of a statement that has been provided as an input by the user","metadata":{}},{"cell_type":"markdown","source":"# Introduction\nOnline forums and social media platforms have provided individuals with the means to put forward their thoughts and freely express their opinion on various issues and incidents. In some cases, these online comments contain explicit language which may hurt the readers. Comments containing explicit language can be classified into myriad categories such as Toxic, Severe Toxic, Obscene, Threat, Insult, and Identity Hate. The threat of abuse and harassment means that many people stop expressing themselves and give up on seeking different opinions.\nTo protect users from being exposed to offensive language on online forums or social media sites, companies have started flagging comments and blocking users who are found guilty of using unpleasant language. Several Machine Learning models have been developed and deployed to filter out the unruly language and protect internet users from becoming victims of online harassment and cyberbullying.","metadata":{}},{"cell_type":"markdown","source":"We will build a model model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s","metadata":{}},{"cell_type":"markdown","source":"# Our Problem is divided into 2 main phases :\n* Modeling\n* Deploy in a website","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"# Problem Statement\n* “To build a multi-headed model that’s capable of detecting different types of toxicity like threats, obscenity, insults, and identity-based hate.”","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{"_kg_hide-output":true}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm_notebook\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom tqdm import tqdm\ntqdm.pandas()\nfrom wordcloud import STOPWORDS\nfrom plotly.subplots import make_subplots\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\nimport re\nfrom tqdm import tqdm_notebook\n\nfrom nltk.corpus import stopwords\n\nfrom tensorflow.keras import regularizers, initializers, optimizers, callbacks\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:38.043746Z","iopub.execute_input":"2022-03-15T04:11:38.044495Z","iopub.status.idle":"2022-03-15T04:11:38.060803Z","shell.execute_reply.started":"2022-03-15T04:11:38.044449Z","shell.execute_reply":"2022-03-15T04:11:38.059309Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\ntest_labels = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip')\nsubmission= pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:38.062857Z","iopub.execute_input":"2022-03-15T04:11:38.063509Z","iopub.status.idle":"2022-03-15T04:11:41.066784Z","shell.execute_reply.started":"2022-03-15T04:11:38.063469Z","shell.execute_reply":"2022-03-15T04:11:41.066009Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:41.068102Z","iopub.execute_input":"2022-03-15T04:11:41.068514Z","iopub.status.idle":"2022-03-15T04:11:41.119784Z","shell.execute_reply.started":"2022-03-15T04:11:41.068476Z","shell.execute_reply":"2022-03-15T04:11:41.118839Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train['characters length'] = train['comment_text'].apply(len)\ntrain['words length'] = train['comment_text'].apply(lambda x: len(x.split()))\ntest['characters length'] = test['comment_text'].apply(len)\ntest['words length'] = test['comment_text'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:41.122027Z","iopub.execute_input":"2022-03-15T04:11:41.122677Z","iopub.status.idle":"2022-03-15T04:11:42.605763Z","shell.execute_reply.started":"2022-03-15T04:11:41.122639Z","shell.execute_reply":"2022-03-15T04:11:42.605011Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# Characters Length Distribution Train","metadata":{}},{"cell_type":"code","source":"print(train['characters length'].describe())\nfig = px.histogram(train, x='characters length', marginal='box')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:42.607049Z","iopub.execute_input":"2022-03-15T04:11:42.607316Z","iopub.status.idle":"2022-03-15T04:11:43.207687Z","shell.execute_reply.started":"2022-03-15T04:11:42.607281Z","shell.execute_reply":"2022-03-15T04:11:43.207007Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# Characters Length Distribution Test","metadata":{}},{"cell_type":"code","source":"print(test['characters length'].describe())\nfig = px.histogram(test, x='characters length', marginal='box')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:43.208807Z","iopub.execute_input":"2022-03-15T04:11:43.209130Z","iopub.status.idle":"2022-03-15T04:11:44.342658Z","shell.execute_reply.started":"2022-03-15T04:11:43.209099Z","shell.execute_reply":"2022-03-15T04:11:44.342047Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_train = train[\"comment_text\"]\nlist_sentences_test = test[\"comment_text\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:44.344156Z","iopub.execute_input":"2022-03-15T04:11:44.344582Z","iopub.status.idle":"2022-03-15T04:11:44.381815Z","shell.execute_reply.started":"2022-03-15T04:11:44.344547Z","shell.execute_reply":"2022-03-15T04:11:44.380920Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:11:44.384533Z","iopub.execute_input":"2022-03-15T04:11:44.384774Z","iopub.status.idle":"2022-03-15T04:12:12.069192Z","shell.execute_reply.started":"2022-03-15T04:11:44.384740Z","shell.execute_reply":"2022-03-15T04:12:12.068442Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"maxlen = 200\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:12:12.072541Z","iopub.execute_input":"2022-03-15T04:12:12.072828Z","iopub.status.idle":"2022-03-15T04:12:14.657342Z","shell.execute_reply.started":"2022-03-15T04:12:12.072783Z","shell.execute_reply":"2022-03-15T04:12:14.656599Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:12:14.659980Z","iopub.execute_input":"2022-03-15T04:12:14.660262Z","iopub.status.idle":"2022-03-15T04:12:14.675923Z","shell.execute_reply.started":"2022-03-15T04:12:14.660210Z","shell.execute_reply":"2022-03-15T04:12:14.675184Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# finaly Starting building Model\n**This is the architecture of the model we are trying to build. It's always to good idea to list out the dimensions of each layer in the model to think visually and help you to debug later on.**\n![](https://i.imgur.com/txJomEa.png)","metadata":{}},{"cell_type":"markdown","source":"# Model Creation (LSTM)\nIt is now time to choose a deep-learning model and train the model using the train-set and the validation-set. Since we are working on a Natural Language Processing use-case, it is ideal that we use the Long Short Term Memory model (LSTM). LSTM networks are similar to RNNs with one major difference that hidden layer updates are replaced by memory cells. This makes them better at finding and exposing long-range dependencies in data which is imperative for sentence structures ","metadata":{}},{"cell_type":"code","source":"inp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\nembed_size = 128\nx = Embedding(max_features, embed_size)(inp)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:12:14.677084Z","iopub.execute_input":"2022-03-15T04:12:14.677804Z","iopub.status.idle":"2022-03-15T04:12:14.695403Z","shell.execute_reply.started":"2022-03-15T04:12:14.677672Z","shell.execute_reply":"2022-03-15T04:12:14.694585Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\nx = GlobalMaxPool1D()(x)\nx = Dropout(0.1)(x)\nx = Dense(50, activation=\"relu\")(x)\n#x = Dense(50, activation=\"sigmoid\")(x) less perfermance\nx = Dropout(0.1)(x)\nx = Dense(6, activation=\"sigmoid\")(x)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:12:14.697329Z","iopub.execute_input":"2022-03-15T04:12:14.697692Z","iopub.status.idle":"2022-03-15T04:12:14.920683Z","shell.execute_reply.started":"2022-03-15T04:12:14.697570Z","shell.execute_reply":"2022-03-15T04:12:14.919858Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:12:14.922153Z","iopub.execute_input":"2022-03-15T04:12:14.922423Z","iopub.status.idle":"2022-03-15T04:12:14.936153Z","shell.execute_reply.started":"2022-03-15T04:12:14.922388Z","shell.execute_reply":"2022-03-15T04:12:14.935033Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 4\nmodel.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:12:14.937716Z","iopub.execute_input":"2022-03-15T04:12:14.937967Z","iopub.status.idle":"2022-03-15T04:16:38.452753Z","shell.execute_reply.started":"2022-03-15T04:12:14.937933Z","shell.execute_reply":"2022-03-15T04:16:38.452037Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:16:38.454328Z","iopub.execute_input":"2022-03-15T04:16:38.454792Z","iopub.status.idle":"2022-03-15T04:16:38.465218Z","shell.execute_reply.started":"2022-03-15T04:16:38.454754Z","shell.execute_reply":"2022-03-15T04:16:38.464099Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"print('Number of entries in each category:')\nprint('training: ', y_train.sum(axis=0))\nprint('validation: ', y_val.sum(axis=0))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T04:16:38.467104Z","iopub.execute_input":"2022-03-15T04:16:38.467513Z","iopub.status.idle":"2022-03-15T04:16:38.477718Z","shell.execute_reply.started":"2022-03-15T04:16:38.467475Z","shell.execute_reply":"2022-03-15T04:16:38.476847Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"#  Part 2 of the Toxic Comment Classifier project\n* this Notebook aims to elaborate on the steps needed to successfully deploy a Deep Learning model on AWS EC2.\n![](https://miro.medium.com/max/1002/1*tbmc4Zub9udxVp1twG43qQ.png)","metadata":{}},{"cell_type":"markdown","source":"# Problem Statement\n**To develop a web application which accurately calculates the toxicity of a statement that has been provided as an input by the user.**","metadata":{}},{"cell_type":"markdown","source":"**Having created and generated all the requisite files for the deployment process, I downloaded the necessary applications needed to complete the deployment, created an account on AWS, and lastly, deployed my application using AWS EC2 instance. Every step followed to achieve successful deployment of my LSTM model will be elaborated in the upon below:**","metadata":{}},{"cell_type":"markdown","source":"**1 - Create an account on Amazon Web Services and log into your account. As soon as you log in, search for EC2 in the search bar that appears on top of the AWS Management Console. Upon choosing “EC2”, you are redirected to the EC2 management console wherein you can click on “Instances” from the Resources tab.**\n![](https://miro.medium.com/max/1400/1*PRh9JVfUMlI_3f36WpKTbA.png)\n","metadata":{}},{"cell_type":"markdown","source":"**There is other steps for finishing the deployement but it is guided by the AWS platform For more details follows this link:**\n[full guide](https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/)","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n**Deploying the LSTM model using a cloud technology, AWS EC2 .\nIn our Case we try to build a model that detect toxic words from sentences even Our application(web for now) will be extended to become a google app that can use for many use cases like child protection or anti_bullying in social media**","metadata":{}},{"cell_type":"markdown","source":"# Database\n* [toxic_database](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n* [glove](https://www.kaggle.com/authman/pickled-glove840b300d-for-10sec-loading)","metadata":{}}]}